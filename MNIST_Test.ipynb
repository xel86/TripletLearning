{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sxWiU50-C7W"
      },
      "source": [
        "Steps to take for MNIST Test:\n",
        "\n",
        "\n",
        "\n",
        "1.   Train MNIST encoder/decoder to accurately predict images\n",
        "2.   Test MNIST encoder accuracy\n",
        "3.   Implement triplet function into pytorch\n",
        "4.   Create loss function based on triplet function\n",
        "5.   Simulate researcher feedback with triplet labels with certain metacriteria\n",
        "6.   Repeat steps 1-5 until triplet labels increase the accuracy of the encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3HplOh6IDFD"
      },
      "source": [
        "Questions:\n",
        "\n",
        "\n",
        "*   Why do we need to reproduce images? Would testing based on prediction accuracy be enough to show results?\n",
        "  \n",
        "  * Hud: was thinking about this some more. For MNIST, you probably can skip the pre-training step because we have plenty of data. Can go straight to training based on triplet feedback. \n",
        "  * Hud: we will need pre-training in the real-world scenario because we expect to be able to get quite a limited set of labels from our researchers. \n",
        "*   Will the retraining after feedback be solely based on feedback labels? Or also based on the triplet probability function? Or also based on \n",
        "\n",
        "  * Hud: training will involve both the model's confidence prediction for an input triplet (which will involve the triplet probability distribution) as well as the ground truth labels (which will involve the feedback labels. \n",
        "\n",
        "      1. pass each sample in triplet through encoder (could even be a simple linear encoder for the first attempt). \n",
        "      2. input encodings into triplet probability function to compute model confidence that triplet evaluates to \"True\"\n",
        "      3. using output of 2 and known True/false value for triplet compute the binary cross entropy loss. \n",
        "    * This process is repeated for all of the training samples. \n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDbJtpbFA-Zx"
      },
      "source": [
        "# Note on training:\n",
        "\n",
        "Rather than data being the image and target being the correct value, the data will be three images and the target will be which image is more similar to the first image.\n",
        "\n",
        "Create a custom dataset with PyTorch using the 3 images as the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RRfisl-96d1",
        "cellView": "both",
        "outputId": "12368a1f-db6e-4051-be26-49d97c7143e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# @title Installs and imports\n",
        "\n",
        "# installs\n",
        "!pip install torchviz\n",
        "\n",
        "# Library imports\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchviz import make_dot\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import math\n",
        "%matplotlib inline\n",
        "\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsQfpCSWaEVQ",
        "cellView": "both",
        "outputId": "acb3528c-7c41-4bf4-d3f4-eb8d642307bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Model and Training Settings\n",
        "batch_size=64 #input batch size for training (default: 64)\n",
        "test_batch_size=1000 #input batch size for testing (default: 1000)\n",
        "epochs=5 #number of epochs to train (default: 14)\n",
        "lr=1.0 #learning rate (default: 1.0)\n",
        "gamma=0.7 #Learning rate step gamma (default: 0.7)\n",
        "no_cuda=False #disables CUDA training (default: True)\n",
        "seed=42 #random seed (default: 42)\n",
        "log_interval=70 #how many batches to wait before logging training status (default: 10)\n",
        "save_model=False #save the trained model (default: False)\n",
        "\n",
        "# additional derived settings\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "print(\"Device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYA_iyl2b5dt"
      },
      "source": [
        "#Creating a Custom Dataset\n",
        "Where the inputs are:\n",
        "*   List of triple indices to use for training\n",
        "*   Original training set\n",
        "*   Function for evaluating meta-criteria\n",
        "\n",
        "And the output is:\n",
        "*   ((A: image,B: image,C: image), target: bool)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6FRAILwaGrn",
        "cellView": "both"
      },
      "source": [
        "# @title Loading the data (instantiating DataLoaders)\n",
        "# define pytorch dataloaders for training and testing\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KnNgRL_ntXA"
      },
      "source": [
        "dataset = datasets.MNIST('../data')\n",
        "indices = []\n",
        "for i in range(100):\n",
        "  indices.append(np.random.randint(0, high=len(dataset.data), size = 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93xKtOUDlagl"
      },
      "source": [
        "def metacriteria(a, b, c):\n",
        "  if(a == b and a != c):\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXWmeVeRpaki"
      },
      "source": [
        "def output(indices, dataset):\n",
        "  #metacriteria go brrr\n",
        "  for triplet in indices:\n",
        "    a,b,c = triplet\n",
        "    if metacriteria(dataset.targets[a].item(), dataset.targets[b].item(), dataset.targets[c].item()):\n",
        "      print(f\"Triplet a: {dataset.targets[a].item()}, b: {dataset.targets[b].item()}, c: {dataset.targets[c].item()} fits metacriteria\")\n",
        "    else:\n",
        "      print(f\"Triplet a: {dataset.targets[a].item()}, b: {dataset.targets[b].item()}, c: {dataset.targets[c].item()} does not fit metacriteria\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFiPQ4fgr845",
        "outputId": "22cb381b-7bb3-4928-beeb-41e824d48371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output(indices, dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Triplet a: 5, b: 6, c: 8 does not fit metacriteria\n",
            "Triplet a: 4, b: 2, c: 5 does not fit metacriteria\n",
            "Triplet a: 6, b: 2, c: 6 does not fit metacriteria\n",
            "Triplet a: 2, b: 1, c: 1 does not fit metacriteria\n",
            "Triplet a: 3, b: 5, c: 0 does not fit metacriteria\n",
            "Triplet a: 5, b: 2, c: 4 does not fit metacriteria\n",
            "Triplet a: 6, b: 2, c: 4 does not fit metacriteria\n",
            "Triplet a: 2, b: 7, c: 7 does not fit metacriteria\n",
            "Triplet a: 7, b: 9, c: 7 does not fit metacriteria\n",
            "Triplet a: 2, b: 3, c: 2 does not fit metacriteria\n",
            "Triplet a: 9, b: 1, c: 6 does not fit metacriteria\n",
            "Triplet a: 3, b: 5, c: 9 does not fit metacriteria\n",
            "Triplet a: 3, b: 9, c: 2 does not fit metacriteria\n",
            "Triplet a: 2, b: 7, c: 4 does not fit metacriteria\n",
            "Triplet a: 3, b: 8, c: 3 does not fit metacriteria\n",
            "Triplet a: 4, b: 4, c: 1 fits metacriteria\n",
            "Triplet a: 7, b: 8, c: 3 does not fit metacriteria\n",
            "Triplet a: 2, b: 0, c: 8 does not fit metacriteria\n",
            "Triplet a: 9, b: 5, c: 3 does not fit metacriteria\n",
            "Triplet a: 4, b: 8, c: 8 does not fit metacriteria\n",
            "Triplet a: 1, b: 6, c: 1 does not fit metacriteria\n",
            "Triplet a: 5, b: 3, c: 3 does not fit metacriteria\n",
            "Triplet a: 6, b: 4, c: 4 does not fit metacriteria\n",
            "Triplet a: 8, b: 5, c: 7 does not fit metacriteria\n",
            "Triplet a: 4, b: 0, c: 2 does not fit metacriteria\n",
            "Triplet a: 6, b: 2, c: 2 does not fit metacriteria\n",
            "Triplet a: 4, b: 1, c: 0 does not fit metacriteria\n",
            "Triplet a: 5, b: 4, c: 9 does not fit metacriteria\n",
            "Triplet a: 9, b: 9, c: 3 fits metacriteria\n",
            "Triplet a: 9, b: 0, c: 6 does not fit metacriteria\n",
            "Triplet a: 2, b: 3, c: 5 does not fit metacriteria\n",
            "Triplet a: 4, b: 1, c: 7 does not fit metacriteria\n",
            "Triplet a: 3, b: 7, c: 9 does not fit metacriteria\n",
            "Triplet a: 4, b: 4, c: 0 fits metacriteria\n",
            "Triplet a: 1, b: 8, c: 2 does not fit metacriteria\n",
            "Triplet a: 0, b: 7, c: 4 does not fit metacriteria\n",
            "Triplet a: 1, b: 4, c: 0 does not fit metacriteria\n",
            "Triplet a: 3, b: 9, c: 9 does not fit metacriteria\n",
            "Triplet a: 9, b: 1, c: 4 does not fit metacriteria\n",
            "Triplet a: 6, b: 1, c: 8 does not fit metacriteria\n",
            "Triplet a: 2, b: 7, c: 5 does not fit metacriteria\n",
            "Triplet a: 1, b: 5, c: 0 does not fit metacriteria\n",
            "Triplet a: 9, b: 9, c: 1 fits metacriteria\n",
            "Triplet a: 5, b: 6, c: 7 does not fit metacriteria\n",
            "Triplet a: 1, b: 6, c: 7 does not fit metacriteria\n",
            "Triplet a: 3, b: 3, c: 3 does not fit metacriteria\n",
            "Triplet a: 2, b: 9, c: 0 does not fit metacriteria\n",
            "Triplet a: 8, b: 3, c: 8 does not fit metacriteria\n",
            "Triplet a: 7, b: 6, c: 4 does not fit metacriteria\n",
            "Triplet a: 1, b: 7, c: 9 does not fit metacriteria\n",
            "Triplet a: 0, b: 6, c: 8 does not fit metacriteria\n",
            "Triplet a: 9, b: 5, c: 0 does not fit metacriteria\n",
            "Triplet a: 8, b: 9, c: 3 does not fit metacriteria\n",
            "Triplet a: 1, b: 0, c: 5 does not fit metacriteria\n",
            "Triplet a: 1, b: 7, c: 2 does not fit metacriteria\n",
            "Triplet a: 6, b: 7, c: 2 does not fit metacriteria\n",
            "Triplet a: 1, b: 6, c: 1 does not fit metacriteria\n",
            "Triplet a: 7, b: 1, c: 2 does not fit metacriteria\n",
            "Triplet a: 8, b: 2, c: 5 does not fit metacriteria\n",
            "Triplet a: 2, b: 1, c: 4 does not fit metacriteria\n",
            "Triplet a: 6, b: 5, c: 0 does not fit metacriteria\n",
            "Triplet a: 1, b: 8, c: 2 does not fit metacriteria\n",
            "Triplet a: 1, b: 0, c: 2 does not fit metacriteria\n",
            "Triplet a: 2, b: 7, c: 4 does not fit metacriteria\n",
            "Triplet a: 1, b: 4, c: 1 does not fit metacriteria\n",
            "Triplet a: 3, b: 5, c: 0 does not fit metacriteria\n",
            "Triplet a: 8, b: 5, c: 5 does not fit metacriteria\n",
            "Triplet a: 5, b: 2, c: 3 does not fit metacriteria\n",
            "Triplet a: 6, b: 8, c: 7 does not fit metacriteria\n",
            "Triplet a: 7, b: 8, c: 2 does not fit metacriteria\n",
            "Triplet a: 6, b: 0, c: 7 does not fit metacriteria\n",
            "Triplet a: 9, b: 7, c: 7 does not fit metacriteria\n",
            "Triplet a: 8, b: 8, c: 4 fits metacriteria\n",
            "Triplet a: 4, b: 3, c: 1 does not fit metacriteria\n",
            "Triplet a: 8, b: 9, c: 6 does not fit metacriteria\n",
            "Triplet a: 2, b: 8, c: 0 does not fit metacriteria\n",
            "Triplet a: 1, b: 8, c: 1 does not fit metacriteria\n",
            "Triplet a: 2, b: 1, c: 8 does not fit metacriteria\n",
            "Triplet a: 7, b: 0, c: 8 does not fit metacriteria\n",
            "Triplet a: 7, b: 6, c: 0 does not fit metacriteria\n",
            "Triplet a: 9, b: 2, c: 3 does not fit metacriteria\n",
            "Triplet a: 0, b: 2, c: 9 does not fit metacriteria\n",
            "Triplet a: 1, b: 3, c: 0 does not fit metacriteria\n",
            "Triplet a: 8, b: 0, c: 5 does not fit metacriteria\n",
            "Triplet a: 9, b: 3, c: 8 does not fit metacriteria\n",
            "Triplet a: 4, b: 7, c: 4 does not fit metacriteria\n",
            "Triplet a: 4, b: 0, c: 2 does not fit metacriteria\n",
            "Triplet a: 2, b: 7, c: 8 does not fit metacriteria\n",
            "Triplet a: 3, b: 1, c: 3 does not fit metacriteria\n",
            "Triplet a: 7, b: 1, c: 4 does not fit metacriteria\n",
            "Triplet a: 7, b: 4, c: 5 does not fit metacriteria\n",
            "Triplet a: 8, b: 1, c: 9 does not fit metacriteria\n",
            "Triplet a: 3, b: 0, c: 3 does not fit metacriteria\n",
            "Triplet a: 0, b: 3, c: 1 does not fit metacriteria\n",
            "Triplet a: 9, b: 1, c: 6 does not fit metacriteria\n",
            "Triplet a: 2, b: 6, c: 2 does not fit metacriteria\n",
            "Triplet a: 7, b: 0, c: 6 does not fit metacriteria\n",
            "Triplet a: 3, b: 7, c: 1 does not fit metacriteria\n",
            "Triplet a: 4, b: 1, c: 0 does not fit metacriteria\n",
            "Triplet a: 9, b: 8, c: 7 does not fit metacriteria\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n36_Tzi5sHim"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8et6eIMcY8E"
      },
      "source": [
        "#Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T48pLwI76Krr"
      },
      "source": [
        "#@title Training and testing functions\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # print(output.shape)\n",
        "        # print(target.shape)\n",
        "        # raise Exception()\n",
        "        loss = F.mse_loss(output.flatten(), data.flatten())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # if batch_idx % log_interval == 0:\n",
        "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        #         epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        #         100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.mse_loss(output.flatten(), data.flatten(), reduction='sum').item()  # sum up batch loss\n",
        "            #pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            #correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJvQCJjVv7Je"
      },
      "source": [
        "# Define the Flatten architecture\n",
        "class NetFlat(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetFlat, self).__init__()\n",
        "\n",
        "        # feature encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(), # Convert into tabular data format.\n",
        "            nn.Linear(784, 10)\n",
        "        )\n",
        "\n",
        "        self.nonlinear = nn.ReLU()\n",
        "        \n",
        "        # decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(10, 784)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x) # Flatten -> x_i\n",
        "        #x = self.nonlinear(x) \n",
        "        x = self.decoder(x) # Matrix multiply -> c_m^0 + sum(W_mi*x_i)\n",
        "\n",
        "\n",
        "        return x.view((-1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVES3olCv-BT",
        "outputId": "fb5ce86a-7ecf-4472-a96c-42abae8ef365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Create the flat model\n",
        "modelLin = NetFlat().to(device)\n",
        "display(modelLin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NetFlat(\n",
              "  (encoder): Sequential(\n",
              "    (0): Flatten()\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "  )\n",
              "  (nonlinear): ReLU()\n",
              "  (decoder): Sequential(\n",
              "    (0): Linear(in_features=10, out_features=784, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQNW81vhwDk4",
        "outputId": "7704b9b5-e462-4d49-fd2b-9145def68e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Get number of free parameters\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "\n",
        "print(\"Number of parameters in linear model:\", get_n_params(modelLin))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in linear model: 16474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXjPjpwgwHEi",
        "outputId": "f84e1248-0590-4f81-9239-16bb0749c6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# @title Train the linear model\n",
        "optimizer = optim.Adadelta(modelLin.parameters(), lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(modelLin, device, train_loader, optimizer, epoch)\n",
        "    test(modelLin, device, test_loader)\n",
        "    scheduler.step()\n",
        "\n",
        "if save_model:\n",
        "    torch.save(modelLin.state_dict(), \"mnist_flat.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 487.5377, Accuracy: 0/10000 (0.00%)\n",
            "Test set: Average loss: 435.9507, Accuracy: 0/10000 (0.00%)\n",
            "Test set: Average loss: 389.4391, Accuracy: 0/10000 (0.00%)\n",
            "Test set: Average loss: 372.0756, Accuracy: 0/10000 (0.00%)\n",
            "Test set: Average loss: 362.4109, Accuracy: 0/10000 (0.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sij5HtQt6FVg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}